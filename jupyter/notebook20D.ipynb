{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Summary:\n",
    "#Total proteins in Biogrid DB (only human-human interaction):                                                16,109\n",
    "#Total number of unique interactions in Biogrid DB (only human-human interaction and no self-interactions): 219,216\n",
    "#Total number of interactions in Biogrid DB (only human-human interaction and no self-interactions):        301,448\n",
    "#Max possible interactions between 16,109 proteins (excluding self interactions):                       129,741,886\n",
    "#Number of elements in adjacency matrix:                                                                259,499,881"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import scipy.spatial\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "\n",
    "from time import time\n",
    "import sys\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start until shortest pathlengths: 1321.8183352947235\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "\n",
    "np.random.seed(100)\n",
    "K = 15\n",
    "Kmax = 16\n",
    "dimen = 20\n",
    "\n",
    "# Read Biogrid data into pandas dataframe\n",
    "df = pd.read_table(\"~/work/BIOGRID-ORGANISM-Homo_sapiens-3.4.147.mitab.txt\", engine=\"c\")\n",
    "\n",
    "# Rename first two columns of dataframe\n",
    "df = df.rename(columns={'#ID Interactor A': 'ID Interactor A'})\n",
    "df['ID Interactor A'] = df['ID Interactor A'].map(lambda x: x.lstrip('entrez gene/locuslink:'))\n",
    "df['ID Interactor B'] = df['ID Interactor B'].map(lambda x: x.lstrip('entrez gene/locuslink:'))\n",
    "\n",
    "\n",
    "# Remove non-human ppi from the dataframe\n",
    "df = df[df['Taxid Interactor A'].isin(['taxid:9606'])]\n",
    "df = df[df['Taxid Interactor B'].isin(['taxid:9606'])]\n",
    "\n",
    "# Remove self interactions\n",
    "df = df[df['ID Interactor A'] != df['ID Interactor B']]\n",
    "\n",
    "# Create networkx graph from dataframe (single edge)\n",
    "G = nx.from_pandas_dataframe(df, 'ID Interactor A', 'ID Interactor B', create_using=nx.Graph())\n",
    "\n",
    "# Determine total number of proteins in the network\n",
    "N = G.number_of_nodes()\n",
    "\n",
    "# Calculate shortest pathlengths dictionary in the graph up to a threshold using networkx\n",
    "p = nx.all_pairs_shortest_path_length(G,K)\n",
    "t2 = time()\n",
    "\n",
    "print(\"Start until shortest pathlengths:\",t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest pathlength up to while loop: 142.53799557685852\n"
     ]
    }
   ],
   "source": [
    "# Reformat path lengths to array\n",
    "dist_df_orig = pd.DataFrame.from_dict(p)\n",
    "dist_df = dist_df_orig.replace(0,2)\n",
    "dist_df = dist_df.fillna(0)-Kmax\n",
    "dist_df[dist_df == -Kmax] = 0\n",
    "dist_mat = dist_df.values\n",
    "\n",
    "sum = np.expand_dims(np.sum(dist_mat,1),1)\n",
    "sumsum = np.sum(dist_mat)\n",
    "\n",
    "vdiff = np.ones((dimen,1))\n",
    "vdiffmax = 1\n",
    "count = 0\n",
    "\n",
    "v = []\n",
    "vnew = []\n",
    "vdiff = []\n",
    "Av = []\n",
    "mv = np.zeros(dimen)\n",
    "lam = np.zeros(dimen)\n",
    "xvals = np.zeros((N,dimen))\n",
    "\n",
    "for i in range(dimen):\n",
    "\tv.append(np.random.randn(N,1))\n",
    "\tvnew.append(np.zeros((N,1)))\n",
    "\tvdiff.append(np.zeros((N,1)))\n",
    "\tAv.append(np.zeros((N,1)))\n",
    "\n",
    "t3=time()\n",
    "\n",
    "print(\"Shortest pathlength up to while loop:\", t3-t2)\n",
    "\n",
    "while vdiffmax > 0.001:\n",
    "\n",
    "\tfor i in range(dimen):\n",
    "\t\tmv[i] = np.mean(v[i])\n",
    "\t\tvnew[i] = -0.5*(np.dot(dist_mat,v[i]) - np.multiply(mv[i],sum) + (mv[i]*sumsum/N - np.multiply(np.multiply(np.dot(sum.T,v[i]),1/N).item(),np.ones((N,1)))))\n",
    "\n",
    "\tvnew[0] /= np.linalg.norm(vnew[0],2)\n",
    "\n",
    "\tfor i in range(1,dimen):\n",
    "\t\tpom = np.zeros(vnew[i].shape)\n",
    "\n",
    "\t\tfor j in range(i):\n",
    "\t\t\tpom += np.dot(np.dot(vnew[j],vnew[i].T),vnew[j])\n",
    "\n",
    "\t\tvnew[i] -= pom\n",
    "\t\tvnew[i] /= np.linalg.norm(vnew[i],2)\n",
    "\n",
    "\tcount += 1\n",
    "\n",
    "\tfor i in range(dimen):\n",
    "\t\tvdiff[i] = np.linalg.norm(v[i] - vnew[i],2)\n",
    "\n",
    "\tvdiffmax = max(vdiff)\n",
    "\t#print(vdiffmax)\n",
    "\n",
    "\tfor i in range(dimen):\n",
    "\t\tv[i] = vnew[i]\n",
    "\n",
    "\n",
    "for i in range(dimen):\n",
    "\tmv[i] = np.mean(v[i])\n",
    "\n",
    "\tAv[i] = -0.5*(dist_mat.dot(v[i]) - mv[i]*sum + (mv[i]*sumsum/N - (np.dot(sum.T,v[i])*(1/N)).item()*np.ones((N,1))))\n",
    "\tlam[i] = np.dot(v[i].T,Av[i])\n",
    "\n",
    "\txvals[:,i] = np.squeeze(np.sqrt(lam[i]) * v[i])\n",
    "\txvals[:,i] -= xvals[:,i].min()\n",
    "\txvals[:,i] /= xvals[:,i].max()\n",
    "\n",
    "t4=time()\n",
    "\n",
    "print(\"While loop until end:\", t4-t3)\n",
    "\n",
    "print(\"Total time:\", t4-t1)\n",
    "\n",
    "print(xvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot 2D embedding\n",
    "plt.scatter(xvals[:,0],xvals[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create list of protein labels corresponding to embedding output and dict to link names to indices and vice versa\n",
    "names = np.array(dist_df_orig.columns, dtype=int)\n",
    "index_dic = dict(enumerate(names))\n",
    "inverse_dic = {v: k for k, v in index_dic.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create adjacency df from distance df and convert to 1D\n",
    "adj_df = copy.copy(dist_df_orig)\n",
    "adj_df[adj_df!=1.0] = 0\n",
    "adj_mat = adj_df.values\n",
    "indices = np.triu_indices_from(adj_mat,k=1)\n",
    "one_d = adj_mat[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate distances between all points\n",
    "distances = scipy.spatial.distance.cdist(xvals,xvals)\n",
    "one_d_dist = distances[np.triu_indices_from(distances,k=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of zero distances\n",
    "print(\"Number of zero distances: \",len(one_d[np.nonzero(one_d_dist==0)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate metrics (threshold independent)\n",
    "inv_one_d_dist = 1/one_d_dist\n",
    "inv_one_d_dist[inv_one_d_dist == np.inf] = 0\n",
    "print(\"ROC AUC: \",sklearn.metrics.roc_auc_score(one_d,inv_one_d_dist))\n",
    "print(\"PRC AUC: \",sklearn.metrics.average_precision_score(one_d,inv_one_d_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace distances with binary labels according to a threshold\n",
    "one_d_thresh_ind = one_d_dist > 0.001\n",
    "one_d_dist_bin = copy.copy(one_d_dist)\n",
    "one_d_dist_bin[one_d_thresh_ind] = 0\n",
    "one_d_dist_bin[np.invert(one_d_thresh_ind)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate proportion of 1 in embedded labels\n",
    "#dict(zip(np.unique(one_d_dist_bin, return_counts=True)[0],np.unique(one_d_dist_bin, return_counts=True)[1]))\n",
    "print(\"Number of predicted interactions at this threshold: \", np.sum(one_d_dist_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate metrics (threshold dependent)\n",
    "print(\"Precision: \",sklearn.metrics.precision_score(one_d,one_d_dist_bin))\n",
    "print(\"Accuracy: \",sklearn.metrics.accuracy_score(one_d,one_d_dist_bin))\n",
    "print(\"Matthews Corr Coeff: \",sklearn.metrics.matthews_corrcoef(one_d,one_d_dist_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print ROCurve\n",
    "roc=sklearn.metrics.roc_curve(one_d,inv_one_d_dist)\n",
    "plt.plot(roc[0],roc[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print PRCurve\n",
    "prc=sklearn.metrics.precision_recall_curve(one_d,inv_one_d_dist)\n",
    "plt.plot(prc[0],prc[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace distances with binary labels according to a threshold\n",
    "one_d_thresh_ind = one_d_dist > 1.0\n",
    "one_d_dist_bin = copy.copy(one_d_dist)\n",
    "one_d_dist_bin[one_d_thresh_ind] = 0\n",
    "one_d_dist_bin[np.invert(one_d_thresh_ind)] = 1\n",
    "\n",
    "# Calculate proportion of 1 in embedded labels\n",
    "#dict(zip(np.unique(one_d_dist_bin, return_counts=True)[0],np.unique(one_d_dist_bin, return_counts=True)[1]))\n",
    "print(\"Number of predicted interactions at this threshold: \", np.sum(one_d_dist_bin))\n",
    "      \n",
    "# Calculate metrics (threshold dependent)\n",
    "print(\"Precision: \",sklearn.metrics.precision_score(one_d,one_d_dist_bin))\n",
    "print(\"Accuracy: \",sklearn.metrics.accuracy_score(one_d,one_d_dist_bin))\n",
    "print(\"Matthews Corr Coeff: \",sklearn.metrics.matthews_corrcoef(one_d,one_d_dist_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace distances with binary labels according to a threshold\n",
    "one_d_thresh_ind = one_d_dist > 0.1\n",
    "one_d_dist_bin = copy.copy(one_d_dist)\n",
    "one_d_dist_bin[one_d_thresh_ind] = 0\n",
    "one_d_dist_bin[np.invert(one_d_thresh_ind)] = 1\n",
    "\n",
    "# Calculate proportion of 1 in embedded labels\n",
    "#dict(zip(np.unique(one_d_dist_bin, return_counts=True)[0],np.unique(one_d_dist_bin, return_counts=True)[1]))\n",
    "print(\"Number of predicted interactions at this threshold: \", np.sum(one_d_dist_bin))\n",
    "      \n",
    "# Calculate metrics (threshold dependent)\n",
    "print(\"Precision: \",sklearn.metrics.precision_score(one_d,one_d_dist_bin))\n",
    "print(\"Accuracy: \",sklearn.metrics.accuracy_score(one_d,one_d_dist_bin))\n",
    "print(\"Matthews Corr Coeff: \",sklearn.metrics.matthews_corrcoef(one_d,one_d_dist_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace distances with binary labels according to a threshold\n",
    "one_d_thresh_ind = one_d_dist > 0.01\n",
    "one_d_dist_bin = copy.copy(one_d_dist)\n",
    "one_d_dist_bin[one_d_thresh_ind] = 0\n",
    "one_d_dist_bin[np.invert(one_d_thresh_ind)] = 1\n",
    "\n",
    "# Calculate proportion of 1 in embedded labels\n",
    "#dict(zip(np.unique(one_d_dist_bin, return_counts=True)[0],np.unique(one_d_dist_bin, return_counts=True)[1]))\n",
    "print(\"Number of predicted interactions at this threshold: \", np.sum(one_d_dist_bin))\n",
    "      \n",
    "# Calculate metrics (threshold dependent)\n",
    "print(\"Precision: \",sklearn.metrics.precision_score(one_d,one_d_dist_bin))\n",
    "print(\"Accuracy: \",sklearn.metrics.accuracy_score(one_d,one_d_dist_bin))\n",
    "print(\"Matthews Corr Coeff: \",sklearn.metrics.matthews_corrcoef(one_d,one_d_dist_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
