{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda0: Tesla K80 (0000:04:00.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate dummy data\n",
    "x_train = np.random.random((1000, 20))\n",
    "y_train = np.random.randint(2, size=(1000, 1))\n",
    "x_test = np.random.random((100, 20))\n",
    "y_test = np.random.randint(2, size=(100, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=20, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.7359     \n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.7184     \n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.7139     \n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.7131     \n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6945     \n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.7005     \n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6960     \n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.7025     \n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6992     \n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.7006     \n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6967     \n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6898     \n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6949     \n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6957     \n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6992     \n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6949     \n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6934     \n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6911     \n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6937     \n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6900     \n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6897     \n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6887     \n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6884     \n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6890     \n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6887     \n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6882     \n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6901     \n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6867     \n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6870     \n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6865     \n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6871     \n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6882     \n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6851     \n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6869     \n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6893     \n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6908     \n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6812     \n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6858     \n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6890     \n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6877     \n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6835     \n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6839     \n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6837     \n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6825     \n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6893     \n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6809     \n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6815     \n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6797     \n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6835     \n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6769     \n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6782     \n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6769     \n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6771     \n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6738     \n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.664 - 0s - loss: 0.6744     \n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6872     \n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6837     \n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6739     \n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6754     \n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6706     \n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6838     \n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6800     \n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6745     \n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6748     \n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6719     \n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6791     \n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6760     \n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6719     \n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6775     \n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6700     \n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6718     \n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6704     \n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6755     \n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6652     \n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6694     \n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6765     \n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6681     \n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6762     \n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6670     \n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6639     \n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6716     \n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6633     \n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6667     \n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6612     \n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6628     \n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6642     \n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6535     \n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6598     \n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6582     \n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6609     \n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6659     \n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6559     \n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6549     \n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6632     \n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6620     \n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6571     \n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6566     \n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6479     \n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.661 - 0s - loss: 0.6570     \n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6521     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe4a18ba390>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.69887441396713257, 0.47999998927116394]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                1344      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,569.0\n",
      "Trainable params: 5,569.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class_name': 'Dense',\n",
       "  'config': {'activation': 'relu',\n",
       "   'activity_regularizer': None,\n",
       "   'batch_input_shape': (None, 20),\n",
       "   'bias_constraint': None,\n",
       "   'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "   'bias_regularizer': None,\n",
       "   'dtype': 'float32',\n",
       "   'kernel_constraint': None,\n",
       "   'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "    'config': {'distribution': 'uniform',\n",
       "     'mode': 'fan_avg',\n",
       "     'scale': 1.0,\n",
       "     'seed': None}},\n",
       "   'kernel_regularizer': None,\n",
       "   'name': 'dense_4',\n",
       "   'trainable': True,\n",
       "   'units': 64,\n",
       "   'use_bias': True}},\n",
       " {'class_name': 'Dropout',\n",
       "  'config': {'name': 'dropout_3', 'rate': 0.5, 'trainable': True}},\n",
       " {'class_name': 'Dense',\n",
       "  'config': {'activation': 'relu',\n",
       "   'activity_regularizer': None,\n",
       "   'bias_constraint': None,\n",
       "   'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "   'bias_regularizer': None,\n",
       "   'kernel_constraint': None,\n",
       "   'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "    'config': {'distribution': 'uniform',\n",
       "     'mode': 'fan_avg',\n",
       "     'scale': 1.0,\n",
       "     'seed': None}},\n",
       "   'kernel_regularizer': None,\n",
       "   'name': 'dense_5',\n",
       "   'trainable': True,\n",
       "   'units': 64,\n",
       "   'use_bias': True}},\n",
       " {'class_name': 'Dropout',\n",
       "  'config': {'name': 'dropout_4', 'rate': 0.5, 'trainable': True}},\n",
       " {'class_name': 'Dense',\n",
       "  'config': {'activation': 'sigmoid',\n",
       "   'activity_regularizer': None,\n",
       "   'bias_constraint': None,\n",
       "   'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "   'bias_regularizer': None,\n",
       "   'kernel_constraint': None,\n",
       "   'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "    'config': {'distribution': 'uniform',\n",
       "     'mode': 'fan_avg',\n",
       "     'scale': 1.0,\n",
       "     'seed': None}},\n",
       "   'kernel_regularizer': None,\n",
       "   'name': 'dense_6',\n",
       "   'trainable': True,\n",
       "   'units': 1,\n",
       "   'use_bias': True}}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Dense at 0x7fe4aa42b940>,\n",
       " <keras.layers.core.Dropout at 0x7fe4aa42b9e8>,\n",
       " <keras.layers.core.Dense at 0x7fe4aa4352e8>,\n",
       " <keras.layers.core.Dropout at 0x7fe4aa3e9cc0>,\n",
       " <keras.layers.core.Dense at 0x7fe4a22f8198>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()\n",
    "model.layers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
